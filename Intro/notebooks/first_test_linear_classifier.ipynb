{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREMIERS PAS EN PYTORCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import progressbar\n",
    "import tqdm\n",
    "import sys\n",
    "from torch.utils.tensorboard import (\n",
    "    SummaryWriter,\n",
    ")  # dashboard local, dashboard en ligne permet de travailler à plusieurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = os.path.join(os.path.expanduser(\"~\"), \"Datasets\", \"FashionMNIST\")\n",
    "valid_ratio = 0.2  # Going to use 80%/20% split for train/valid\n",
    "\n",
    "# Load the dataset for the training/validation sets\n",
    "train_valid_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root=dataset_dir,\n",
    "    train=True,\n",
    "    transform=None,  # transforms.ToTensor(),\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "# Split it into training and validation sets\n",
    "nb_train = int((1.0 - valid_ratio) * len(train_valid_dataset))\n",
    "nb_valid = int(valid_ratio * len(train_valid_dataset))\n",
    "train_dataset, valid_dataset = torch.utils.data.dataset.random_split(\n",
    "    train_valid_dataset, [nb_train, nb_valid]\n",
    ")\n",
    "\n",
    "\n",
    "# Load the test set\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root=dataset_dir, transform=None, train=False  # transforms.ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données convertir en tensor\n",
    "tensor : mémoire RAM cpu / gpu d'ou le .to(device), qui l'envoie sur le la ram du device\n",
    "\n",
    "tenseur : nom plus général pour matrice de dimension n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DatasetTransformer est une classe qui prends un Dataset et une fonction qui permet de transformer une donnée dans le type voulu. \n",
    "\n",
    "get_item retourne l'item dans le type voulu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetTransformer(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, base_dataset, transform):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.base_dataset[index]\n",
    "        return self.transform(img), target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DatasetTransformer(train_dataset, transforms.ToTensor())\n",
    "valid_dataset = DatasetTransformer(valid_dataset, transforms.ToTensor())\n",
    "test_dataset = DatasetTransformer(test_dataset, transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### création des Dataloaders pour les 3 parties de notre base de donnée\n",
    "\n",
    "train, test, validation grâce à DataLoader de pytorch. c'est ici qu'on choisi stocastique mini-bacth batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_threads = 4  # Loading the dataset is using 4 CPU threads\n",
    "batch_size = 128  # Using minibatches of 128 samples si le dernier mini_batch <128, c'est pas grave, ca fait un mini_batch petit. Faire attention dans le training ( voir % accuracy)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,  # <-- this reshuffles the data at every epoch\n",
    "    num_workers=num_threads,\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    dataset=valid_dataset, batch_size=batch_size, shuffle=False, num_workers=num_threads\n",
    ")\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_threads\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On teste si les données sont bien loader. ensuite on affiche quelques images de plusieurs classe de notre dataset train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set contains 48000 images, in 375 batches\n",
      "The validation set contains 12000 images, in 94 batches\n",
      "The test set contains 10000 images, in 79 batches\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"The train set contains {} images, in {} batches\".format(\n",
    "        len(train_loader.dataset), len(train_loader)\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"The validation set contains {} images, in {} batches\".format(\n",
    "        len(valid_loader.dataset), len(valid_loader)\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"The test set contains {} images, in {} batches\".format(\n",
    "        len(test_loader.dataset), len(test_loader)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nsamples = 10\n",
    "classes_names = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "imgs, labels = next(iter(train_loader))\n",
    "\n",
    "fig = plt.figure(figsize=(20, 5), facecolor=\"w\")\n",
    "for i in range(nsamples):\n",
    "    ax = plt.subplot(1, nsamples, i + 1)\n",
    "    plt.imshow(imgs[i, 0, :, :], vmin=0, vmax=1.0, cmap=cm.gray)\n",
    "    ax.set_title(\"{}\".format(classes_names[labels[i]]), fontsize=15)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.savefig(\"fashionMNIST_samples.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construction du modèle linear classifier\n",
    "\n",
    "linearNet, une couche linéaire de taille input_size,num_classes. \n",
    "\n",
    "Initialisation des weight and biais de tensor : eights and biases are initialized with a uniform distribution : uniform(-1/sqrt(in_features), 1/sqrt(in_features)).\n",
    "In_features : linar(in_feat,out_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(Batch, channel, Height, width) (torch mais attention (channel,h,w,batch)).\n",
    "\n",
    "linear couche (\\*, data) -> (\\*, data) il prend en compte la dernière dimension du tensor (x.size()[0] ou x.shape[0] -1 plus modulable si tensor taille 1,2,3,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNet(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.classifier = nn.Linear(self.input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(\n",
    "            x.size()[0], -1\n",
    "        )  # voir markdown au dessus ! nb_images,image_size*channel en vect\n",
    "        y = self.classifier(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALTERNATIVE POUR ne pas faire de classe pour le réseau de neuronnes // tensorflow exemple :\n",
    "\n",
    "**model = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))**\n",
    "\n",
    "ALTERNATIVE POUR initialiser les poids à la main : \n",
    "\n",
    "**model.apply(init_weights)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on accède via cuda aux GPU dédiés, si il y en a pas, cpu. Ca permet d'envoyer les tensor sur le device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearNet(\n",
       "  (classifier): Linear(in_features=784, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearNet(1 * 28 * 28, 10)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Test Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### traning loop \n",
    "\n",
    "\n",
    "\n",
    "enumerate dans la boucle for utile pour récuperer les éléments et l'indice de range(len(M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, f_loss, optimizer, device):\n",
    "    \"\"\"\n",
    "    Train a model for one epoch, iterating over the loader\n",
    "    using the f_loss to compute the loss and the optimizer\n",
    "    to update the parameters of the model.\n",
    "\n",
    "    Arguments :\n",
    "\n",
    "        model     -- A torch.nn.Module object\n",
    "        loader    -- A torch.utils.data.DataLoader\n",
    "        f_loss    -- The loss function, i.e. a loss Module\n",
    "        optimizer -- A torch.optim.Optimzer object\n",
    "        device    -- a torch.device class specifying the device\n",
    "                     used for computation\n",
    "\n",
    "    Returns :\n",
    "    \"\"\"\n",
    "\n",
    "    # We enter train mode. This is useless for the linear model\n",
    "    # but is important for layers such as dropout, batchnorm, ...\n",
    "    # dropout mask de 0 ou 1 pour eviter l'overfitting x <- x* mask\n",
    "    model.train()\n",
    "    # with tqdm.tqdm(loader, unit=\"batch\") as tepoch:\n",
    "    for i, (inputs, targets) in enumerate(loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # Compute the forward pass through the network up to the loss\n",
    "        outputs = model(inputs)\n",
    "        loss = f_loss(outputs, targets)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # val_loss, val_acc = test(model, valid_loader, f_loss, device)\n",
    "        # tepoch.set_postfix(loss = val_loss, accuracy=100. * val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross entropy => Yk score de dim (nb pixels +1 (biais) ) Z = softmax(ji) in [0,9] zk = exp(yk)/sum(exp(yi))\n",
    "\n",
    "Loss_cross =  -log(Zy_i)\n",
    "\n",
    "pas de softmax layer, exp facilement trop grand. pytorch = MLL o softmax\n",
    "\n",
    "LogSumExpTrick pour stabilité numérique: \n",
    "\n",
    " zk = exp(yk - max(yi))/sum(exp(yi)- max(yj)) |\n",
    "Loss_cross = yk -c  -log(sum(exp(yi)- max(yj)))\n",
    "\n",
    "ici pas de one hot encoding, classes de 0 à 9\n",
    "\n",
    "pour récup des probas a la main, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader, f_loss, device):\n",
    "    \"\"\"\n",
    "    Test a model by iterating over the loader\n",
    "\n",
    "    Arguments :\n",
    "\n",
    "        model     -- A torch.nn.Module object\n",
    "        loader    -- A torch.utils.data.DataLoader\n",
    "        f_loss    -- The loss function, i.e. a loss Module\n",
    "        device    -- The device to use for computation\n",
    "\n",
    "    Returns :\n",
    "\n",
    "        A tuple with the mean loss and mean accuracy\n",
    "\n",
    "    \"\"\"\n",
    "    # We disable gradient computation which speeds up the computation\n",
    "    # and reduces the memory usage\n",
    "    with torch.no_grad():\n",
    "        # We enter evaluation mode. This is useless for the linear model\n",
    "        # but is important with layers such as dropout, batchnorm, ..\n",
    "        model.eval()\n",
    "        N = 0\n",
    "        tot_loss, correct = 0.0, 0.0\n",
    "        for i, (inputs, targets) in enumerate(loader):\n",
    "\n",
    "            # We got a minibatch from the loader within inputs and targets\n",
    "            # With a mini batch size of 128, we have the following shapes\n",
    "            #    inputs is of shape (128, 1, 28, 28)\n",
    "            #    targets is of shape (128)\n",
    "\n",
    "            # We need to copy the data on the GPU if we use one\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # Compute the forward pass, i.e. the scores for each input image\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # We accumulate the exact number of processed samples\n",
    "            N += inputs.shape[0]\n",
    "\n",
    "            # We accumulate the loss considering\n",
    "            # The multipliation by inputs.shape[0] is due to the fact\n",
    "            # that our loss criterion is averaging over its samples\n",
    "            tot_loss += inputs.shape[0] * f_loss(outputs, targets).item()\n",
    "\n",
    "            # For the accuracy, we compute the labels for each input image\n",
    "            # Be carefull, the model is outputing scores and not the probabilities\n",
    "            # But given the softmax is not altering the rank of its input scores\n",
    "            # we can compute the label by argmaxing directly the scores\n",
    "            predicted_targets = outputs.argmax(dim=1)\n",
    "            correct += (predicted_targets == targets).sum().item()\n",
    "        return tot_loss / N, correct / N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      " Validation : Loss : 0.5743, Acc : 0.8131\n",
      "Epoch 1\n",
      " Validation : Loss : 0.5137, Acc : 0.8295\n",
      "Epoch 2\n",
      " Validation : Loss : 0.4847, Acc : 0.8378\n",
      "Epoch 3\n",
      " Validation : Loss : 0.4670, Acc : 0.8438\n",
      "Epoch 4\n",
      " Validation : Loss : 0.4558, Acc : 0.8467\n",
      "Epoch 5\n",
      " Validation : Loss : 0.4471, Acc : 0.8489\n",
      "Epoch 6\n",
      " Validation : Loss : 0.4450, Acc : 0.8492\n",
      "Epoch 7\n",
      " Validation : Loss : 0.4369, Acc : 0.8522\n",
      "Epoch 8\n",
      " Validation : Loss : 0.4300, Acc : 0.8551\n",
      "Epoch 9\n",
      " Validation : Loss : 0.4298, Acc : 0.8537\n",
      "Epoch 10\n",
      " Validation : Loss : 0.4279, Acc : 0.8532\n",
      "Epoch 11\n",
      " Validation : Loss : 0.4228, Acc : 0.8558\n",
      "Epoch 12\n",
      " Validation : Loss : 0.4230, Acc : 0.8553\n",
      "Epoch 13\n",
      " Validation : Loss : 0.4222, Acc : 0.8562\n",
      "Epoch 14\n",
      " Validation : Loss : 0.4258, Acc : 0.8542\n",
      "Epoch 15\n",
      " Validation : Loss : 0.4220, Acc : 0.8551\n",
      "Epoch 16\n",
      " Validation : Loss : 0.4237, Acc : 0.8543\n",
      "Epoch 17\n",
      " Validation : Loss : 0.4219, Acc : 0.8576\n",
      "Epoch 18\n",
      " Validation : Loss : 0.4232, Acc : 0.8548\n",
      "Epoch 19\n",
      " Validation : Loss : 0.4174, Acc : 0.8588\n",
      "Epoch 20\n",
      " Validation : Loss : 0.4215, Acc : 0.8559\n",
      "Epoch 21\n",
      " Validation : Loss : 0.4224, Acc : 0.8570\n",
      "Epoch 22\n",
      " Validation : Loss : 0.4170, Acc : 0.8568\n",
      "Epoch 23\n",
      " Validation : Loss : 0.4322, Acc : 0.8526\n",
      "Epoch 24\n",
      " Validation : Loss : 0.4173, Acc : 0.8557\n",
      "Epoch 25\n",
      " Validation : Loss : 0.4257, Acc : 0.8558\n",
      "Epoch 26\n",
      " Validation : Loss : 0.4253, Acc : 0.8553\n",
      "Epoch 27\n",
      " Validation : Loss : 0.4174, Acc : 0.8569\n",
      "Epoch 28\n",
      " Validation : Loss : 0.4153, Acc : 0.8586\n",
      "Epoch 29\n",
      " Validation : Loss : 0.4205, Acc : 0.8551\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch {}\".format(epoch))\n",
    "    train(model, train_loader, f_loss, optimizer, device)\n",
    "    val_loss, val_acc = test(model, valid_loader, f_loss, device)\n",
    "    print(\" Validation : Loss : {:.4f}, Acc : {:.4f}\".format(val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarder un modèle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/linear_8\n",
      "Logging to ./logs/linear_9\n"
     ]
    }
   ],
   "source": [
    "def generate_unique_logpath(logdir, raw_run_name):\n",
    "    i = 0\n",
    "    while True:\n",
    "        run_name = raw_run_name + \"_\" + str(i)\n",
    "        log_path = os.path.join(logdir, run_name)\n",
    "        if not os.path.isdir(log_path):\n",
    "            return log_path\n",
    "        i = i + 1\n",
    "\n",
    "\n",
    "###################################################\n",
    "# Example usage :\n",
    "# 1- create the directory \"./logs\" if it does not exist\n",
    "top_logdir = \"./logs\"\n",
    "if not os.path.exists(top_logdir):\n",
    "    os.mkdir(top_logdir)\n",
    "\n",
    "# 2- We test the function by calling several times our function\n",
    "logdir = generate_unique_logpath(top_logdir, \"linear\")\n",
    "print(\"Logging to {}\".format(logdir))\n",
    "# -> Prints out     Logging to   ./logs/linear_0\n",
    "if not os.path.exists(logdir):\n",
    "    os.mkdir(logdir)\n",
    "\n",
    "logdir = generate_unique_logpath(top_logdir, \"linear\")\n",
    "print(\"Logging to {}\".format(logdir))\n",
    "# -> Prints out     Logging to   ./logs/linear_1\n",
    "if not os.path.exists(logdir):\n",
    "    os.mkdir(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCheckpoint:\n",
    "\n",
    "    def __init__(self, filepath, model):\n",
    "        self.min_loss = None\n",
    "        self.filepath = filepath\n",
    "        self.model = model\n",
    "\n",
    "    def update(self, loss):\n",
    "        if (self.min_loss is None) or (loss < self.min_loss):\n",
    "            print(\"Saving a better model\")\n",
    "            torch.save(self.model.state_dict(), self.filepath)\n",
    "            # torch.save(self.model, self.filepath)\n",
    "            self.min_loss = loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajout de la sauvegarde du modèle. on garde le meilleur modèle en fonction du corpus de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "Epoch 0\n",
      " Validation : Loss : 0.5753, Acc : 0.8130\n",
      "Saving a better model\n",
      "Epoch 1\n",
      " Validation : Loss : 0.5089, Acc : 0.8290\n",
      "Saving a better model\n",
      "Epoch 2\n",
      " Validation : Loss : 0.4929, Acc : 0.8338\n",
      "Saving a better model\n",
      "Epoch 3\n",
      " Validation : Loss : 0.4656, Acc : 0.8440\n",
      "Saving a better model\n",
      "Epoch 4\n",
      " Validation : Loss : 0.4564, Acc : 0.8446\n",
      "Saving a better model\n",
      "Epoch 5\n",
      " Validation : Loss : 0.4493, Acc : 0.8487\n",
      "Saving a better model\n",
      "Epoch 6\n",
      " Validation : Loss : 0.4414, Acc : 0.8528\n",
      "Saving a better model\n",
      "Epoch 7\n",
      " Validation : Loss : 0.4364, Acc : 0.8529\n",
      "Saving a better model\n",
      "Epoch 8\n",
      " Validation : Loss : 0.4314, Acc : 0.8546\n",
      "Saving a better model\n",
      "Epoch 9\n",
      " Validation : Loss : 0.4285, Acc : 0.8552\n",
      "Saving a better model\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# Example usage\n",
    "\n",
    "# on sauvegarde le modèle le meilleur vis à vis de tests\n",
    "# Define the callback object\n",
    "\n",
    "## refaire avec un modèle nouveau :\n",
    "model = LinearNet(1 * 28 * 28, 10)\n",
    "model.to(device)\n",
    "## ouvrir un modèle sauvegarder avec torch.save\n",
    "model_path = \"logs/linear_1/best_model.pt\"\n",
    "print(model.load_state_dict(torch.load(model_path)))\n",
    "# Switch to eval mode sinon les poids ne s'accualisent pas\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters()\n",
    ")  ## ATTENTION A METTRE LE BON MODÈLE SI ON RÉINSTANCIE LE MODÈLE !\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(logdir + \"/best_model.pt\", model)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch {}\".format(epoch))\n",
    "    train(model, train_loader, f_loss, optimizer, device)\n",
    "    val_loss, val_acc = test(model, valid_loader, f_loss, device)\n",
    "    print(\" Validation : Loss : {:.4f}, Acc : {:.4f}\".format(val_loss, val_acc))\n",
    "    model_checkpoint.update(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création et Sauvegarde des données autres (texte, tensorboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "même boucle, on rajoute le tensorboard pour avoir des graphiques de notre loss et accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "Epoch 0\n",
      " Validation : Loss : 0.5701, Acc : 0.8168\n",
      "Saving a better model\n",
      "Epoch 1\n",
      " Validation : Loss : 0.5095, Acc : 0.8319\n",
      "Saving a better model\n",
      "Epoch 2\n",
      " Validation : Loss : 0.4805, Acc : 0.8407\n",
      "Saving a better model\n",
      "Epoch 3\n",
      " Validation : Loss : 0.4655, Acc : 0.8448\n",
      "Saving a better model\n",
      "Epoch 4\n",
      " Validation : Loss : 0.4539, Acc : 0.8470\n",
      "Saving a better model\n",
      "Epoch 5\n",
      " Validation : Loss : 0.4488, Acc : 0.8504\n",
      "Saving a better model\n",
      "Epoch 6\n",
      " Validation : Loss : 0.4440, Acc : 0.8502\n",
      "Saving a better model\n",
      "Epoch 7\n",
      " Validation : Loss : 0.4394, Acc : 0.8505\n",
      "Saving a better model\n",
      "Epoch 8\n",
      " Validation : Loss : 0.4324, Acc : 0.8551\n",
      "Saving a better model\n",
      "Epoch 9\n",
      " Validation : Loss : 0.4328, Acc : 0.8537\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "model = LinearNet(1 * 28 * 28, 10)\n",
    "model.to(device)\n",
    "tensorboard_writer = SummaryWriter(log_dir=logdir)\n",
    "## ouvrir un modèle sauvegarder avec torch.save\n",
    "model_path = \"logs/linear_1/best_model.pt\"\n",
    "print(model.load_state_dict(torch.load(model_path)))\n",
    "# Switch to eval mode sinon les poids ne s'accualisent pas\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters()\n",
    ")  ## ATTENTION A METTRE LE BON MODÈLE SI ON RÉINSTANCIE LE MODÈLE !\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(logdir + \"/best_model.pt\", model)\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch {}\".format(epoch))\n",
    "    train(model, train_loader, f_loss, optimizer, device)\n",
    "    train_loss, train_acc = test(model, train_loader, f_loss, device)\n",
    "    val_loss, val_acc = test(model, valid_loader, f_loss, device)\n",
    "    print(\" Validation : Loss : {:.4f}, Acc : {:.4f}\".format(val_loss, val_acc))\n",
    "    model_checkpoint.update(val_loss)\n",
    "    tensorboard_writer.add_scalar(\"metrics/train_loss\", train_loss, epoch)\n",
    "    tensorboard_writer.add_scalar(\"metrics/train_acc\", train_acc, epoch)\n",
    "    tensorboard_writer.add_scalar(\"metrics/val_loss\", val_loss, epoch)\n",
    "    tensorboard_writer.add_scalar(\"metrics/val_acc\", val_acc, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite on sauvegarde le tensorboard pour le garder.\n",
    "\n",
    "Normalement, hors jupyter notebook, tout ce relance d'un coup donc il y a un nouveau dossier log a chaque execution. \n",
    "\n",
    "COMMANDE DE VISUALISATION : tensorboard --logdir ./logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_file = open(logdir + \"/summary.txt\", \"w\")\n",
    "summary_text = \"\"\"\n",
    "\n",
    "Executed command\n",
    "================\n",
    "{}\n",
    "\n",
    "Dataset\n",
    "=======\n",
    "FashionMNIST\n",
    "\n",
    "Model summary\n",
    "=============\n",
    "{}\n",
    "\n",
    "{} trainable parameters\n",
    "\n",
    "Optimizer\n",
    "========\n",
    "{}\n",
    "\n",
    "\"\"\".format(\n",
    "    \" \".join(sys.argv),\n",
    "    model,\n",
    "    sum(p.numel() for p in model.parameters() if p.requires_grad),\n",
    "    optimizer,\n",
    ")\n",
    "summary_file.write(summary_text)\n",
    "summary_file.close()\n",
    "\n",
    "\n",
    "tensorboard_writer.add_text(\"Experiment summary\", summary_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalisation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "première étape : définir la fonction qui permet de normaliser. Elle n'existe pas dans Torch contrairement à d'autres librairies.\n",
    "\n",
    "Torch utilise un transformer, qui transforme les données selon une fonction. (transformer est général)\n",
    "\n",
    "Si problème convexe, une seul solutions, mais avec les differents lancements où dirait qu'il y a plusieurs minimum global : \n",
    "il est possible que nom standardisation fait que l'apprentissage n'est pas égal. a sauvegarder aussi les pré-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_std(loader):\n",
    "    # Compute the mean over minibatches\n",
    "    mean_img = None\n",
    "    for imgs, _ in loader:\n",
    "        if mean_img is None:\n",
    "            mean_img = torch.zeros_like(imgs[0])\n",
    "        mean_img += imgs.sum(dim=0)\n",
    "    mean_img /= len(loader.dataset)\n",
    "\n",
    "    # Compute the std over minibatches\n",
    "    std_img = torch.zeros_like(mean_img)\n",
    "    for imgs, _ in loader:\n",
    "        std_img += ((imgs - mean_img) ** 2).sum(dim=0)\n",
    "    std_img /= len(loader.dataset)\n",
    "    std_img = torch.sqrt(std_img)\n",
    "\n",
    "    # Set the variance of pixels with no variance to 1\n",
    "    # Because there is no variance\n",
    "    # these pixels will anyway have no impact on the final decision\n",
    "    std_img[std_img == 0] = 1\n",
    "\n",
    "    return mean_img, std_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transformation des données avec transforms.Compose : \n",
    "\n",
    "on récupère la moyenne et la variance sur TRAIN uniquement ! Eviter biais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizing_dataset = train_dataset\n",
    "normalizing_loader = torch.utils.data.DataLoader(\n",
    "    dataset=normalizing_dataset, batch_size=batch_size, num_workers=num_threads\n",
    ")\n",
    "\n",
    "# Compute mean and variance from the training set\n",
    "mean_train_tensor, std_train_tensor = compute_mean_std(normalizing_loader)\n",
    "\n",
    "\n",
    "data_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: (x - mean_train_tensor) / std_train_tensor),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = DatasetTransformer(train_dataset, data_transforms)\n",
    "valid_dataset = DatasetTransformer(valid_dataset, data_transforms)\n",
    "test_dataset = DatasetTransformer(test_dataset, data_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Fully connected 2 hidden layers classifier\n",
    "voir le fichier : \n",
    "2_layer_model.py pour voir A Fully connected 2 hidden layers classifier. \n",
    "\n",
    "commentaires ici et sur le .py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sur la régularisation\n",
    "\n",
    "idée : eviter le surapprentissage. Comment ?\n",
    "\n",
    "- sur les données : \n",
    "    -data augmentation\n",
    "    - new datasets\n",
    "\n",
    "- sur le modèle :\n",
    "    - coefficient d'apprentissage qui prennent en compte le poids du noeud  (L2 régularisation par exemple)\n",
    "    - batch normalisation (normalise xi, en entre // data normalisation, ou dans le modèle n'importe ou)\n",
    "    - dropout "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## envoyer en file sur DCE les entrainement en parallèle\n",
    "\n",
    "exemple usage -> starting batch trainins in NN\n",
    "\n",
    "node always 1 prod long = 48h / prod nuit = 12h //permet aussi de faire 4 jobs pas user plutot que 1.\n",
    "\n",
    "array = combien de lancement\n",
    "\n",
    "interet de la version avec git : choisir la version de code a tester pour pouvoir continuer à coder sans soucis.\n",
    "\n",
    "avec copie du git et checkout la bonne version. requirements.txt pour faire un pip env spécifique.\n",
    "\n",
    "ssh 2023avr_5@dce.metz.centrale.supelec.fr \n",
    "\n",
    "ssh 2023avr_5@chome.metz.supelec.fr\n",
    "\n",
    "password : SingletonsGarrisonsRoguishly\n",
    "\n",
    "argparse pour les parametres tuto dedans\n",
    "\n",
    "byobu\n",
    "\n",
    "squeue (voir jobs)\n",
    "scancel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
